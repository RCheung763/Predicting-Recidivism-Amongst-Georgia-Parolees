{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9P87pKO3PuBR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NIJ's Recidivism Challenge\n",
        "\n",
        "[Codebook](https://nij.ojp.gov/funding/recidivism-forecasting-challenge#19-0)"
      ],
      "metadata": {
        "id": "RaMYmtN2ZMaO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sDS5oPvWJJj"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "from pandas.plotting import parallel_coordinates\n",
        "\n",
        "from sklearn.cluster import \\\n",
        "     (KMeans,\n",
        "      AgglomerativeClustering)\n",
        "from scipy.cluster.hierarchy import \\\n",
        "     (dendrogram,\n",
        "      cut_tree)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load, Filtering, Adjusting"
      ],
      "metadata": {
        "id": "v5a91szPWeEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data\n",
        "url = \"https://raw.githubusercontent.com/gringler8/data5322project/main/NIJ_s_Recidivism_Challenge_Full_Dataset_20240520.csv\"\n",
        "data = pd.read_csv(url)\n",
        "print(data.head())\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "4NifpLGWWNgo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to filter NAs\n",
        "columns_to_check = [\n",
        "    'Avg_Days_per_DrugTest',\n",
        "    'DrugTests_THC_Positive',\n",
        "    'DrugTests_Cocaine_Positive',\n",
        "    'DrugTests_Meth_Positive',\n",
        "    'DrugTests_Other_Positive',\n",
        "    'Percent_Days_Employed',\n",
        "    'Jobs_Per_Year',\n",
        "    'Supervision_Risk_Score_First'\n",
        "]\n",
        "\n",
        "# Filter out rows with NAs in the specified columns\n",
        "filtered_data = data.dropna(subset=columns_to_check).copy()\n",
        "\n",
        "# Convert Supervision_Risk_Score_First to a categorical variable\n",
        "filtered_data.loc[:, 'Supervision_Risk_Score_First'] = filtered_data['Supervision_Risk_Score_First'].astype('category')\n",
        "\n",
        "# Clean and convert Avg_Days_per_DrugTest to float by removing commas\n",
        "filtered_data.loc[:, 'Avg_Days_per_DrugTest'] = filtered_data['Avg_Days_per_DrugTest'].str.replace(',', '').astype(float)\n",
        "filtered_data.loc[:, 'ID'] = filtered_data['ID'].str.replace(',', '').astype(float)\n",
        "\n",
        "# Create Numeric Columns for \"Or More\" columns to cap at the number prior to \"Or More\"\n",
        "column_conditions = {\n",
        "    'Dependents': (3, '3 or more'),\n",
        "    'Prior_Arrest_Episodes_Felony': (10, '10 or more'),\n",
        "    'Prior_Arrest_Episodes_Misd': (6, '6 or more'),\n",
        "    'Prior_Arrest_Episodes_Violent': (3, '3 or more'),\n",
        "    'Prior_Arrest_Episodes_Property': (5, '5 or more'),\n",
        "    'Prior_Arrest_Episodes_Drug': (5, '5 or more'),\n",
        "    'Prior_Arrest_Episodes_PPViolationCharges': (5, '5 or more'),\n",
        "    'Prior_Conviction_Episodes_Felony': (3, '3 or more'),\n",
        "    'Prior_Conviction_Episodes_Misd': (4, '4 or more'),\n",
        "    'Prior_Conviction_Episodes_Prop': (3, '3 or more'),\n",
        "    'Prior_Conviction_Episodes_Drug': (2, '2 or more'),\n",
        "    'Delinquency_Reports': (4, '4 or more'),\n",
        "    'Program_Attendances': (10, '10 or more'),\n",
        "    'Program_UnexcusedAbsences': (3, '3 or more'),\n",
        "    'Residence_Changes': (3, '3 or more')\n",
        "}\n",
        "\n",
        "# Create the numeric columns based on the conditions\n",
        "for column, (numeric_value, condition_str) in column_conditions.items():\n",
        "    numeric_column = column + \"_Numeric\"\n",
        "    filtered_data.loc[:, numeric_column] = filtered_data[column].replace(condition_str, numeric_value).astype(int)\n",
        "\n",
        "print(filtered_data.shape)\n"
      ],
      "metadata": {
        "id": "KOQCaFtAWPV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "BAOFB0RnWaaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the columns for PCA\n",
        "pca_data = filtered_data[[\n",
        "    'Avg_Days_per_DrugTest',\n",
        "    'DrugTests_THC_Positive',\n",
        "    'DrugTests_Cocaine_Positive',\n",
        "    'DrugTests_Meth_Positive',\n",
        "    'DrugTests_Other_Positive',\n",
        "    'Percent_Days_Employed',\n",
        "    'Jobs_Per_Year',\n",
        "]]\n",
        "\n",
        "# Standardize the data by centering and scaling\n",
        "scaler = StandardScaler()\n",
        "pca_data_scaled = scaler.fit_transform(pca_data)\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA()\n",
        "pca_out = pca.fit_transform(pca_data_scaled)\n",
        "\n",
        "# Create a DataFrame to display the mean and scale used in the standardization\n",
        "scaling_info = pd.DataFrame({'Center': scaler.mean_, 'Scale': scaler.scale_}, index=pca_data.columns)\n",
        "print(scaling_info)\n",
        "\n",
        "# Print the number of principal components\n",
        "print(\"Number of Principal Components:\", pca.n_components_)\n",
        "\n",
        "# Explained variance\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Explained Variance:\", explained_variance)\n",
        "\n",
        "# Plot the principal components\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.title('Explained Variance by Principal Components')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3927E4y1WQm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a representative data point for each Supervision_Risk_Score_First\n",
        "representative_points = filtered_data.groupby('Supervision_Risk_Score_First')[pca_data.columns].mean()\n",
        "\n",
        "# Standardize the representative points\n",
        "representative_points_scaled = scaler.transform(representative_points)\n",
        "representative_pca_out = pca.transform(representative_points_scaled)\n",
        "\n",
        "# Plotting the PCA biplot with Supervision Risk Score\n",
        "i, j = 0, 1  # which components to plot\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
        "\n",
        "# Plot the scores for the first two principal components\n",
        "ax.scatter(representative_pca_out[:, i], representative_pca_out[:, j], edgecolor='k', s=100)\n",
        "\n",
        "# Annotate points with Supervision Risk Score\n",
        "for score, pc1, pc2 in zip(representative_points.index, representative_pca_out[:, i], representative_pca_out[:, j]):\n",
        "    ax.annotate(str(int(score)), (pc1, pc2))\n",
        "\n",
        "# Plot principal component loading vectors\n",
        "for k in range(pca.components_.shape[1]):\n",
        "    ax.arrow(0, 0, pca.components_[i, k], pca.components_[j, k], head_width=0.03, head_length=0.05, ec='gray')\n",
        "    ax.text(pca.components_[i, k] * 1.1, pca.components_[j, k] * 1.1, pca_data.columns[k], color='r')\n",
        "\n",
        "ax.set_xlabel('PC%d' % (i + 1))\n",
        "ax.set_ylabel('PC%d' % (j + 1))\n",
        "ax.set_title(\"PCA Biplot with Supervision Risk Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZxBh4604WTOH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA/K-Means Clustering**\n"
      ],
      "metadata": {
        "id": "swh3Pa5-ItcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=4)\n",
        "pca_out = pca.fit_transform(pca_data_scaled)"
      ],
      "metadata": {
        "id": "hzEpL-cwIDoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_out = pca.fit_transform(pca_data_scaled)"
      ],
      "metadata": {
        "id": "e8CO7iypJBTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wcss = []\n",
        "for i in range(1, 15):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "    kmeans.fit(pca_out)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.plot(range(1, 15), wcss, marker = 'o')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aSSr4exyvyqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_kmeans = KMeans(n_clusters=11, init='k-means++', random_state=100)\n",
        "pca_kmeans.fit(pca_out)"
      ],
      "metadata": {
        "id": "C4Kgf-U1GaeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the cluster labels for new dataframe\n",
        "pca_kmeans_data = pca_data.copy()\n",
        "pca_kmeans_data['Cluster'] = pca_kmeans.labels_\n",
        "# Add Component to dataframe\n",
        "pca_kmeans_data = pd.concat([pca_kmeans_data, pd.DataFrame(pca_out)], axis=1)\n",
        "pca_kmeans_data = pca_kmeans_data.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3', 3: 'PC4'})"
      ],
      "metadata": {
        "id": "xxtUXkYMGooH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_feature = 'Jobs_Per_Year'\n",
        "y_feature = 'DrugTests_Other_Positive'\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pca_kmeans_data, x=x_feature, y=y_feature, hue='Cluster', palette='Paired')\n",
        "plt.title('KMeans Clustering')\n",
        "plt.xlabel(x_feature)\n",
        "plt.ylabel(y_feature)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BAj4HVHSHbFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_feature = 'Percent_Days_Employed'\n",
        "y_feature = 'DrugTests_Other_Positive'\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pca_kmeans_data, x=x_feature, y=y_feature, hue='Cluster', palette='Paired')\n",
        "plt.title('KMeans Clustering')\n",
        "plt.xlabel(x_feature)\n",
        "plt.ylabel(y_feature)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LqQ2hDoWLeXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "pca_summary = pca_kmeans_data.drop(['PC1', 'PC2', 'PC3', 'PC4'], axis=1)\n",
        "cluster_count = pca_summary.groupby('Cluster').size()\n",
        "summary = pca_summary.groupby('Cluster').agg(['mean', 'std'])\n",
        "summary = summary.reset_index()  # Reset the index\n",
        "summary = pd.concat([summary, cluster_count.to_frame(name='count')], axis=1)\n",
        "\n",
        "# Renaming the columns for clarity\n",
        "summary.columns = ['_'.join(col) for col in summary.columns]\n",
        "summary"
      ],
      "metadata": {
        "id": "aiM5OzwFkAT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary.to_csv('summary.csv', index=False)"
      ],
      "metadata": {
        "id": "g9ceE2Vnny95"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}